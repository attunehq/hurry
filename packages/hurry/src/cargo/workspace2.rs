use std::{
    collections::{BTreeMap, HashMap},
    fmt::Debug,
    path::PathBuf,
};

use cargo_metadata::TargetKind;
use color_eyre::{
    Result, Section, SectionExt,
    eyre::{Context, OptionExt as _, bail, eyre},
};
use derive_more::Debug as DebugExt;
use scopeguard::defer;
use serde::{Deserialize, Serialize};
use tap::{Pipe as _, Tap as _, TapFallible as _};
use tokio::task::spawn_blocking;
use tracing::{debug, instrument, trace};
use uuid::Uuid;

use crate::{
    cargo::{
        self, BuildPlan, BuildScriptOutput, CargoBuildArguments, CargoCompileMode, Fingerprint,
        Profile, RustcMetadata, build_plan::RustcArgument,
    },
    fs, mk_rel_dir, mk_rel_file,
    path::{AbsDirPath, AbsFilePath, JoinWith as _, TryJoinWith as _},
};

/// The Cargo workspace of a build.
///
/// Workspaces contain all the information needed to unambiguously specify the
/// files in a build. Note that workspaces are constructed with a specific
/// invocation in mind, since we parse some of its configuration fields from a
/// build invocation's arguments.
#[derive(Clone, Eq, PartialEq, Hash, DebugExt, Serialize, Deserialize)]
pub struct Workspace {
    /// The root directory of the workspace.
    pub root: AbsDirPath,

    /// The $CARGO_HOME value.
    pub cargo_home: AbsDirPath,

    /// The build profile of this workspace invocation.
    pub profile: Profile,

    /// The target triple flag of this workspace invocation, if set.
    ///
    /// ## Cross-Compilation Directory Structure
    ///
    /// When cross-compiling with `--target <triple>`, Cargo uses a complex
    /// directory structure that separates host and target artifacts:
    ///
    /// ```not_rust
    /// target/
    /// ├── <triple>/                    ← Target platform artifacts
    /// │   └── <profile>/
    /// │       ├── deps/                ← Compiled libraries (.rlib, .so, etc.)
    /// │       ├── build/               ← Build script OUTPUT directories
    /// │       │   └── pkg-hash/
    /// │       │       └── out/         ← Files generated by build scripts
    /// │       └── .fingerprint/        ← Fingerprints for:
    /// │           ├── pkg-hash1/       ← - Library compilation
    /// │           └── pkg-hash2/       ← - Build script EXECUTION
    /// └── <profile>/                   ← Host platform artifacts
    ///     ├── build/                   ← Build script BINARIES
    ///     │   └── pkg-hash/
    ///     │       └── build-script-*   ← Compiled build script executables
    ///     └── .fingerprint/            ← Fingerprints for:
    ///         └── pkg-hash/            ← - Build script COMPILATION
    /// ```
    ///
    /// ### The Confusing Part: Build Scripts
    ///
    /// Build scripts have a split personality during cross-compilation:
    ///
    /// 1. **Compilation** (host): The build script itself is a Rust program that
    ///    must run on the build machine (host). Its compiled binary and compilation
    ///    fingerprint live in `target/<profile>/` (no triple).
    ///
    /// 2. **Execution** (target): When the build script runs, it generates files
    ///    for the target platform. Its output directory and execution fingerprint
    ///    live in `target/<triple>/<profile>/`.
    ///
    /// This means for a package like `serde` with a build script:
    /// - Binary: `target/debug/build/serde-{hash1}/build-script-build`
    /// - Binary fingerprint: `target/debug/.fingerprint/serde-{hash1}/`
    /// - Output directory:
    ///   `target/aarch64-apple-darwin/debug/build/serde-{hash2}/out/`
    /// - Output fingerprint:
    ///   `target/aarch64-apple-darwin/debug/.fingerprint/serde-{hash2}/`
    ///
    /// Notice that `hash1` (compilation) and `hash2` (execution) are different
    /// because they represent different compilation units with different
    /// dependencies and flags.
    pub target_arch: Option<String>,
}

impl Workspace {
    /// Create a workspace by parsing `cargo metadata` from the given directory.
    #[instrument(name = "Workspace::from_argv_in_dir")]
    pub async fn from_argv_in_dir(
        path: &AbsDirPath,
        args: impl AsRef<CargoBuildArguments> + Debug,
    ) -> Result<Self> {
        let args = args.as_ref();

        let (workspace_root, workspace_target) = {
            // TODO: Maybe we should just replicate this logic and perform it
            // statically using filesystem operations instead of shelling out?
            // This costs something on the order of 200ms, which is not
            // _terrible_ but feels much slower than if we just did our own
            // filesystem reads, especially since we don't actually use any of
            // the logic except the paths.
            let manifest_path = args.manifest_path().map(String::from);
            let cmd_current_dir = path.as_std_path().to_path_buf();
            let metadata = spawn_blocking(move || -> Result<_> {
                cargo_metadata::MetadataCommand::new()
                    .tap_mut(|cmd| {
                        if let Some(p) = manifest_path {
                            cmd.manifest_path(p);
                        }
                    })
                    .current_dir(cmd_current_dir)
                    .exec()
                    .context("exec and parse cargo metadata")
            })
            .await
            .context("join task")?
            .tap_ok(|metadata| debug!(?metadata, "cargo metadata"))
            .context("get cargo metadata")?;
            (
                AbsDirPath::try_from(&metadata.workspace_root)
                    .context("parse workspace root as absolute directory")?,
                AbsDirPath::try_from(&metadata.target_directory)
                    .context("parse workspace target as absolute directory")?,
            )
        };

        let cargo_home = spawn_blocking({
            let workspace_root = workspace_root.clone();
            move || home::cargo_home_with_cwd(workspace_root.as_std_path())
        })
        .await
        .context("join background task")?
        .context("get $CARGO_HOME")?
        .pipe(AbsDirPath::try_from)
        .context("parse path as utf8")?;

        let profile = args.profile().map(Profile::from).unwrap_or(Profile::Debug);
        let target_arch = args.target().map(String::from);

        Ok(Self {
            root: workspace_root,
            cargo_home,
            profile,
            target_arch,
        })
    }

    /// Create a workspace from the current working directory.
    ///
    /// Convenience method that calls `from_argv_in_dir`
    /// using the current working directory as the workspace root.
    #[instrument(name = "Workspace::from_argv")]
    pub async fn from_argv(args: impl AsRef<CargoBuildArguments> + Debug) -> Result<Self> {
        let pwd = AbsDirPath::current().context("get working directory")?;
        Self::from_argv_in_dir(&pwd, args).await
    }

    /// Get the build directory for this workspace. Note that we use the "build
    /// dir" terminology from Cargo's upcoming split between final and
    /// intermediate build artifacts[^1].
    ///
    /// [^1]: https://github.com/rust-lang/cargo/issues/6790
    #[instrument(name = "Workspace::build_dir")]
    pub fn build_dir(&self) -> AbsDirPath {
        // TODO: Support all sorts of configuration flags and environment
        // variables that can modify this directory's location.
        self.root.join(mk_rel_dir!("target"))
    }

    /// Get the profile directory for intermediate build artifacts built for the
    /// host architecture.
    #[instrument(name = "Workspace::host_profile_dir")]
    pub fn host_profile_dir(&self) -> AbsDirPath {
        self.build_dir()
            .try_join_dir(self.profile.as_str())
            .expect("profile should be valid directory name")
    }

    /// Get the profile directory for intermediate build artifacts built for the
    /// target architecture.
    ///
    /// When `--target` is set, this is different from the host profile
    /// directory, and library and build script execution artifacts are stored
    /// in the target profile directory.
    #[instrument(name = "Workspace::target_profile_dir")]
    pub fn target_profile_dir(&self) -> AbsDirPath {
        match &self.target_arch {
            Some(target_arch) => self
                .build_dir()
                .try_join_dirs(vec![target_arch.as_str(), self.profile.as_str()])
                .expect("target arch and profile should be valid directory names"),
            None => self.host_profile_dir(),
        }
    }

    /// Get the build plan by running `cargo build --build-plan` with the
    /// provided arguments.
    #[instrument(name = "Workspace::build_plan")]
    async fn build_plan(
        &self,
        args: impl AsRef<CargoBuildArguments> + std::fmt::Debug,
    ) -> Result<BuildPlan> {
        let build_dir = self.build_dir();

        // Running `cargo build --build-plan` deletes a bunch of items in the `target`
        // directory. To work around this we temporarily move `target` -> run
        // the build plan -> move it back. If the rename fails (e.g., permissions,
        // cross-device), we proceed without it; this will then have the original issue
        // but at least won't break the build.
        let temp = self
            .root
            .try_join_dir(format!("target.backup.{}", Uuid::new_v4()))?;

        let renamed = fs::rename(&build_dir, &temp).await.is_ok();

        defer! {
            if renamed {
                let build_dir = build_dir.as_std_path();
                #[allow(clippy::disallowed_methods, reason = "cannot use async in defer")]
                let _ = std::fs::remove_dir_all(build_dir);
                #[allow(clippy::disallowed_methods, reason = "cannot use async in defer")]
                let _ = std::fs::rename(&temp.as_std_path(), build_dir);
            }
        }

        // From testing locally, it doesn't seem to matter in which order we
        // pass the flags but we pass the user flags first just in case as that
        // seems like it'd follow the principle of least surprise if ordering
        // ever does matter.
        let mut build_args = args.as_ref().to_argv();
        build_args.extend([
            String::from("--build-plan"),
            String::from("-Z"),
            String::from("unstable-options"),
        ]);
        let output = cargo::invoke_output("build", build_args, [("RUSTC_BOOTSTRAP", "1")])
            .await
            .context("run cargo command")?;
        serde_json::from_slice::<BuildPlan>(&output.stdout)
            .context("parse build plan")
            .with_section(move || {
                String::from_utf8_lossy(&output.stdout)
                    .to_string()
                    .header("Stdout:")
            })
            .with_section(move || {
                String::from_utf8_lossy(&output.stderr)
                    .to_string()
                    .header("Stderr:")
            })
    }

    #[instrument(name = "Workspace::artifact_plan")]
    pub async fn artifact_plan(
        &self,
        args: impl AsRef<CargoBuildArguments> + std::fmt::Debug,
    ) -> Result<ArtifactPlan> {
        let rustc = RustcMetadata::from_argv(&self.root, &args)
            .await
            .context("parsing rustc metadata")?;
        trace!(?rustc, "rustc metadata");

        // Note that build plans as a feature are deprecated[^1]. If a stable
        // alternative comes along, we should migrate.
        //
        // An alternative is the `--unit-graph` flag, which is unstable but not
        // deprecated[^2]. Unfortunately, unit graphs do not provide information
        // about the `rustc` invocation argv or the unit hash of the build
        // script execution, both of which are necessary to construct the
        // artifact cache key. We could theoretically reconstruct this
        // information using the JSON build messages and RUSTC_WRAPPER
        // invocation recording, but that's way more work for no stronger of a
        // stability guarantee.
        //
        // [^1]: https://github.com/rust-lang/cargo/issues/7614
        // [^2]: https://doc.rust-lang.org/cargo/reference/unstable.html#unit-graph
        let build_plan = self.build_plan(&args).await?;
        trace!(?build_plan, "build plan");

        let mut units = BTreeMap::new();
        for (i, invocation) in build_plan.invocations.into_iter().enumerate() {}

        Ok(ArtifactPlan { units })
    }
}

/// An ArtifactPlan represents information known about cacheable artifacts that
/// can be known before a build.
pub struct ArtifactPlan {
    // TODO: How to handle fingerprint reconstruction when units can depend on
    // arbitrary other units, even piercing package units?

    // What if we had a separate map for each supported unit type, so we can still
    // have different unit type structs?

    // Or we can just fold it all into one unit type like Cargo does and call it a day.
    units: BTreeMap<u32, PackageUnitPlans>,
}

pub struct PackageUnitPlans {
    pub package_name: String,
    pub package_version: String,

    library_crate: LibraryCrateUnitPlan,
    build_script: Option<BuildScriptUnitPlans>,
    // TODO: In the future, add more supported unit types in a package here
    // (e.g. tests and examples).
}

pub struct LibraryCrateUnitPlan {
    unit_hash: String,
    crate_name: String,
    src_path: AbsFilePath,
    outputs: Vec<AbsFilePath>,
    deps: Vec<u32>,
}

pub struct BuildScriptUnitPlans {
    compilation: BuildScriptCompilationUnitPlan,
    execution: BuildScriptExecutionUnitPlan,
}

pub struct BuildScriptCompilationUnitPlan {
    /// The unit hash of the build script compilation. This is parsed from the
    /// output paths in the unit's build plan invocation.
    unit_hash: String,

    /// The path to the build script's main entrypoint source file. This is
    /// usually `build.rs` within the package's source code, but can vary if the
    /// package author sets `package.build` in the package's `Cargo.toml`, which
    /// changes the build script's name[^1].
    ///
    /// This is parsed from the rustc invocation arguments in the unit's build
    /// plan invocation.
    ///
    /// This is used to rewrite the build script compilation's fingerprint on
    /// restore.
    ///
    /// [^1]: https://doc.rust-lang.org/cargo/reference/manifest.html#the-build-field
    src_path: AbsFilePath,

    /// The path to the compiled outputs of this build script.
    ///
    /// This is parsed from the output paths in the unit's build plan
    /// invocation.
    ///
    /// These file paths must have their mtimes modified to match the
    /// fingerprint's invoked timestamp for the unit to be marked fresh.
    outputs: Vec<AbsFilePath>,

    /// The dependencies of this build script compilation.
    ///
    /// This is parsed from the dependencies in the unit's build plan
    /// invocation.
    ///
    /// This is used to rewrite the build script compilation's fingerprint on
    /// restore.
    deps: Vec<u32>,
}

pub struct BuildScriptExecutionUnitPlan {
    /// The unit hash of the build script execution. This is parsed from the
    /// OUT_DIR in the unit's build plan invocation.
    unit_hash: String,

    /// The OUT_DIR where user-defined build script output files should be
    /// written.
    out_dir: AbsDirPath,

    deps: Vec<u32>,
}

impl BuildScriptExecutionUnitPlan {
    pub fn from_out_dir(out_dir: AbsDirPath) -> Self {
        todo!()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use pretty_assertions::assert_eq as pretty_assert_eq;

    #[tokio::test]
    async fn build_plan_flag_order_does_not_matter() {
        // This is a relatively basic test to start with; if we find other edge
        // cases we want to test we should add them here (or in a similar test).
        let user_args = ["--release"];
        let tool_args = ["--build-plan", "-Z", "unstable-options"];
        let env = [("RUSTC_BOOTSTRAP", "1")];
        let cmd = "build";

        let args = user_args.iter().chain(tool_args.iter());
        let user_args_first = match cargo::invoke_output(cmd, args, env).await {
            Ok(output) => output.stdout,
            Err(e) => panic!("user args first should succeed: {e}"),
        };

        let args = tool_args.iter().chain(user_args.iter());
        let tool_args_first = match cargo::invoke_output(cmd, args, env).await {
            Ok(output) => output.stdout,
            Err(e) => panic!("tool args first should succeed: {e}"),
        };

        let user_plan = serde_json::from_slice::<BuildPlan>(&user_args_first).unwrap();
        let tool_plan = serde_json::from_slice::<BuildPlan>(&tool_args_first).unwrap();
        pretty_assert_eq!(
            user_plan,
            tool_plan,
            "both orderings should produce same build plan"
        );
    }
}
